{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer - convert words into numbers for computer\n",
    "\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "char_to_int = dict()\n",
    "\n",
    "for i in range (len(chars)):\n",
    "    char_to_int[chars[i]] = i + 1\n",
    "\n",
    "char_to_int[\".\"] = 0\n",
    "int_to_chars = [\".\"]+chars\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "Num of examples:  5\n"
     ]
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "\n",
    "    chs = [\".\"] + [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2, ch3, ch4 in zip(chs,chs[1:],chs[2:],chs[3:]):\n",
    "\n",
    "        ind1 = char_to_int[ch1]\n",
    "        ind2 = char_to_int[ch2]\n",
    "        ind3 = char_to_int[ch3]\n",
    "        ind4 = char_to_int[ch4]\n",
    "\n",
    "        xs.append([ind1,ind2,ind3])\n",
    "        ys.append(ind4)\n",
    "\n",
    "        print(\"{}{}{} ----> {}\".format(ch1,ch2,ch3,ch4))\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num_examples = len(xs)\n",
    "print(\"Num of examples: \", num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of params:  3481\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 27\n",
    "context_length = 3\n",
    "embedding_size = 2\n",
    "W1_size = 100\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# Create NN Parameters\n",
    "C = torch.randn((vocab_size,embedding_size), generator=g) #init with small random numbers near zero\n",
    "W1 = torch.randn((context_length*embedding_size,W1_size), generator=g)\n",
    "b1 = torch.randn((W1_size), generator=g)\n",
    "W2 = torch.randn((W1_size,vocab_size), generator=g)\n",
    "b2 = torch.randn((vocab_size), generator=g)\n",
    "\n",
    "params = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in params:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "n_params = sum(p.numel() for p in params)\n",
    "print(\"Num of params: \", n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.941762924194336\n",
      "15.248147964477539\n",
      "8.964353561401367\n",
      "4.224044322967529\n",
      "1.2105400562286377\n",
      "0.29714006185531616\n",
      "0.09521935135126114\n",
      "0.06758875399827957\n",
      "0.053451500833034515\n",
      "0.04457003250718117\n",
      "0.03839101642370224\n",
      "0.03381089121103287\n",
      "0.03026415780186653\n",
      "0.027428239583969116\n",
      "0.02510356903076172\n",
      "0.023160241544246674\n",
      "0.021509408950805664\n",
      "0.020088452845811844\n",
      "0.01885126158595085\n",
      "0.01776372827589512\n",
      "0.016799679026007652\n",
      "0.01593897119164467\n",
      "0.015165427699685097\n",
      "0.014466166496276855\n",
      "0.013830659911036491\n",
      "0.013250870630145073\n",
      "0.012719196267426014\n",
      "0.012230100110173225\n",
      "0.011778381653130054\n",
      "0.01135995052754879\n",
      "0.010971111245453358\n",
      "0.01060895249247551\n",
      "0.01027065608650446\n",
      "0.009953794069588184\n",
      "0.009656643494963646\n",
      "0.009377219714224339\n",
      "0.009113977663218975\n",
      "0.00886558834463358\n",
      "0.008630714379251003\n",
      "0.008408376947045326\n",
      "0.008197424001991749\n",
      "0.007997202686965466\n",
      "0.007806727197021246\n",
      "0.0076254382729530334\n",
      "0.0074525573290884495\n",
      "0.007287570275366306\n",
      "0.007129936013370752\n",
      "0.006979162339121103\n",
      "0.006834803614765406\n",
      "0.00669643422588706\n",
      "0.006563751958310604\n",
      "0.006436426192522049\n",
      "0.0063138678669929504\n",
      "0.006196124013513327\n",
      "0.006082819774746895\n",
      "0.005973671562969685\n",
      "0.005868468899279833\n",
      "0.005766973830759525\n",
      "0.005669117905199528\n",
      "0.005574594717472792\n",
      "0.0054831188172101974\n",
      "0.005394811276346445\n",
      "0.005309293512254953\n",
      "0.005226542241871357\n",
      "0.005146344192326069\n",
      "0.005068677477538586\n",
      "0.004993399605154991\n",
      "0.004920369479805231\n",
      "0.004849444143474102\n",
      "0.004780719988048077\n",
      "0.004713865928351879\n",
      "0.004648880567401648\n",
      "0.00458567077293992\n",
      "0.004524354822933674\n",
      "0.004464601166546345\n",
      "0.00440641026943922\n",
      "0.004349782131612301\n",
      "0.004294622223824263\n",
      "0.004240883979946375\n",
      "0.004188471008092165\n",
      "0.0041374326683580875\n",
      "0.004087577573955059\n",
      "0.004039003513753414\n",
      "0.003991660661995411\n",
      "0.003945312462747097\n",
      "0.0039001021068543196\n",
      "0.0038559348322451115\n",
      "0.003812786191701889\n",
      "0.0037705618888139725\n",
      "0.003729332936927676\n",
      "0.003689005272462964\n",
      "0.003649649675935507\n",
      "0.0036109809298068285\n",
      "0.0035732134710997343\n",
      "0.0035362758208066225\n",
      "0.003500120248645544\n",
      "0.0034646529238671064\n",
      "0.0034299916587769985\n",
      "0.003395970445126295\n",
      "0.003362684976309538\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "\n",
    "for i in range(100):\n",
    "    xs_embed = C[xs]\n",
    "    xs_embed_stack = xs_embed.view(-1,context_length*embedding_size)\n",
    "    # xs_embed_stack = torch.cat((xs_embed[:,0,:],xs_embed[:,1,:],xs_embed[:,2,:]), dim=1)\n",
    "\n",
    "    l1 = torch.tanh(xs_embed_stack @ W1 + b1)\n",
    "    logits = l1 @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, ys) \n",
    "    print(loss.item())\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in params:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Ideas is that we are going to learn the embeddings (is this a encoder v1?)\n",
    "\n",
    "Naively if you feed a=1, b=2, c=3 into the network, then there is a bias as a and b are similar. \n",
    "\n",
    "Instead we can represent each symbol as a point in n-dimensional space. and have the network learn what that point is. We would then expect conceptually similar symbols to be close in space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0])\n",
      "e\n",
      "m\n",
      "m\n",
      "a\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(logits.max(1).indices)\n",
    "\n",
    "for pred in logits.max(1).indices:\n",
    "    print(int_to_chars[pred.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
