{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "generator = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "char_to_int = dict()\n",
    "\n",
    "for i in range (len(chars)):\n",
    "    char_to_int[chars[i]] = i + 1\n",
    "\n",
    "char_to_int[\".\"] = 0\n",
    "int_to_chars = [\".\"]+chars\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "\n",
    "    chs = [\".\"] + [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2, ch3, ch4 in zip(chs,chs[1:],chs[2:],chs[3:]):\n",
    "\n",
    "        ind1 = char_to_int[ch1]\n",
    "        ind2 = char_to_int[ch2]\n",
    "        ind3 = char_to_int[ch3]\n",
    "        ind4 = char_to_int[ch4]\n",
    "\n",
    "        xs.append([ind1,ind2,ind3])\n",
    "        ys.append(ind4)\n",
    "\n",
    "        # print(\"get {}{}{} pred {}\".format(ch1,ch2,ch3,ch4))\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num_examples = len(xs)\n",
    "print(\"Num of examples: \", num_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 27\n",
    "context_length = 3\n",
    "embedding_size = 30\n",
    "W1_size = 100\n",
    "\n",
    "# Define Parameters\n",
    "C = torch.normal(mean=0,std=1, size=(vocab_size,embedding_size)) #init with small random numbers near zero\n",
    "W1 = torch.normal(mean=0,std=1, size=(context_length*embedding_size,W1_size))\n",
    "b1 = torch.normal(mean=0,std=1, size=(W1_size,1))\n",
    "W2 = torch.normal(mean=0,std=1, size=(W1_size,vocab_size))\n",
    "b2 = torch.normal(mean=0,std=1, size=(vocab_size,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0])\n",
      "tensor([ 0.9544,  1.2025,  0.5323,  0.6351, -0.0695, -1.7277, -0.3416, -0.6708,\n",
      "        -1.2427,  0.2587, -0.6534, -0.2738, -0.6583,  0.3233, -2.0614, -0.6998,\n",
      "        -0.5279, -0.3436,  0.9284,  0.0112,  1.4257,  0.1303,  0.2634,  1.0906,\n",
      "         1.1757,  0.8796,  1.6235,  0.1084, -0.4226,  1.0671,  0.9544,  1.2025,\n",
      "         0.5323,  0.6351, -0.0695, -1.7277, -0.3416, -0.6708, -1.2427,  0.2587,\n",
      "        -0.6534, -0.2738, -0.6583,  0.3233, -2.0614, -0.6998, -0.5279, -0.3436,\n",
      "         0.9284,  0.0112,  1.4257,  0.1303,  0.2634,  1.0906,  1.1757,  0.8796,\n",
      "         1.6235,  0.1084, -0.4226,  1.0671,  0.9544,  1.2025,  0.5323,  0.6351,\n",
      "        -0.0695, -1.7277, -0.3416, -0.6708, -1.2427,  0.2587, -0.6534, -0.2738,\n",
      "        -0.6583,  0.3233, -2.0614, -0.6998, -0.5279, -0.3436,  0.9284,  0.0112,\n",
      "         1.4257,  0.1303,  0.2634,  1.0906,  1.1757,  0.8796,  1.6235,  0.1084,\n",
      "        -0.4226,  1.0671])\n",
      "torch.Size([90])\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "\n",
    "#one at a time\n",
    "\n",
    "for i in range(1):\n",
    "    x = xs[i]\n",
    "    x_embed = torch.cat((C[x[0]],C[x[1]],C[x[2]]))\n",
    "    print(x)\n",
    "    print(x_embed)\n",
    "    print(x_embed.shape)\n",
    "    assert(x_embed.shape[0] == context_length*embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
